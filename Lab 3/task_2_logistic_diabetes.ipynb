{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BHdMfFcnf_Ki"
   },
   "source": [
    "## Logistic Regression Modeling for Early Stage Diabetes Risk Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.1: Getting familiar with linear algebraic functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tasks\n",
    "- Create matrix of size 10*10 with random integer numbers\n",
    "- Compute the following linear algebric operations on the matrix using built in functions supported in Numpy, Scipy etc.\n",
    "  - Find inverse of the matrix and print it\n",
    "  - Calculate dot product of the matrix with same matrix in transpose A.AT\n",
    "  - Decompose the original matrix using eigen decomposition print the eigen values and eigen vectors\n",
    "  - Calculate jacobian matrix \n",
    "  - Calculate hessian matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.77054599 -0.28763519  0.7571519   0.77066525 -0.44192557  1.09620001\n",
      "   1.06973528 -0.99789077 -0.15782934 -0.85309718]\n",
      " [ 1.47167029  0.50696603  0.86347052 -0.78669753 -0.62864718  1.98159446\n",
      "   1.16451263  1.42759183  1.61582227 -1.18518868]\n",
      " [ 0.03511474 -0.02885358  0.66270516 -0.05142918  0.99484396  0.86035218\n",
      "   0.76852296 -0.5455213  -0.49289765  0.83617297]\n",
      " [ 0.37054886 -0.44470253 -0.72134538 -0.70353285 -0.05827808 -0.03552508\n",
      "   1.58773023  2.25314568 -0.50480873 -0.61960323]\n",
      " [-0.54703226 -0.07625986  0.52209955 -1.13017803 -0.79332013 -1.34583512\n",
      "  -0.27795412 -0.69960169 -1.34999843 -0.07389336]\n",
      " [ 0.22591812  1.01910762  0.23108596  0.30693304 -1.8301436   0.70454768\n",
      "  -0.55472024  0.606036   -0.54689753  0.17405671]\n",
      " [-0.6284526   0.82979032  0.7665682  -1.3191466  -2.11844414 -0.10249917\n",
      "  -0.58531646 -1.67406301 -1.00748503  0.11054745]\n",
      " [ 0.57408788  0.7502042   0.41613508 -0.38049185 -0.799523    0.33090875\n",
      "  -1.02754074  0.65345781 -1.05193747  0.66616035]\n",
      " [-1.78205581  0.04702526 -0.53798968 -0.45827247  0.70681387 -0.37976431\n",
      "  -0.69977402  0.2989258   1.27504765  0.98353853]\n",
      " [ 0.29457043 -1.68038794 -0.73039004  1.59035091 -0.9132009   0.38412644\n",
      "   0.46926968 -0.20827298 -0.58239889 -0.46658071]]\n"
     ]
    }
   ],
   "source": [
    "mat = np.random.randn(10, 10)\n",
    "mat.shape\n",
    "print(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.36330182,  0.64730186,  0.88739442, -0.70425843,  0.1149768 ,\n",
       "         0.47782538,  0.04226979, -1.23245274, -1.4839623 ,  0.48464839],\n",
       "       [ 0.21282469, -0.36359537, -0.15109821,  0.20205861, -0.46417735,\n",
       "         0.36157589,  0.14037969, -0.27052716, -0.21825519, -0.60931655],\n",
       "       [ 0.17189349,  0.42165445,  0.36504479, -0.48595328,  1.29076059,\n",
       "         0.61908072, -0.85805596, -0.17606811,  0.2637798 ,  0.04206236],\n",
       "       [-0.01452717, -0.07155963,  0.15478882, -0.2505055 ,  0.32903277,\n",
       "         0.75476778, -0.51759131, -0.50021954, -0.09740314,  0.00570856],\n",
       "       [ 1.58340288, -0.54150236, -0.68117285,  0.48387311, -0.47692654,\n",
       "        -0.91974377, -0.00920397,  1.21123234,  0.65991999, -0.53224103],\n",
       "       [ 2.25189424, -0.5688843 , -0.92611907,  0.78039049, -0.99817677,\n",
       "        -1.23334731,  0.49377932,  1.91297647,  1.18732113, -0.31930203],\n",
       "       [-1.71696476,  0.41283107,  1.12826949, -0.29745528,  0.41486581,\n",
       "         1.10321899, -0.07496588, -1.81415122, -0.94447846,  0.25466287],\n",
       "       [ 0.40837029,  0.03211363, -0.14534095,  0.15411229,  0.36718435,\n",
       "         0.17972703, -0.43410711,  0.34588583,  0.3977777 , -0.05498086],\n",
       "       [-1.81992496,  0.7148855 ,  0.72145147, -0.72893947,  0.42508001,\n",
       "         0.76308944, -0.16153608, -1.43809712, -0.70624926,  0.40965331],\n",
       "       [-3.45972732,  0.91420247,  1.93044587, -1.02812255,  0.679695  ,\n",
       "         1.4645756 , -0.15535667, -2.21284773, -1.4557955 ,  0.85895866]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv = np.linalg.inv(mat)\n",
    "inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.1334362   4.06290191  1.7319054  -0.62979415 -1.32307846  0.61323896\n",
      "   0.77379598 -1.18905558 -4.96301556  3.40736329]\n",
      " [ 4.06290191 15.51887815  0.05791361  5.20089365 -5.08817408  2.48305885\n",
      "  -2.50630238  0.28921051 -3.39323019 -1.10384573]\n",
      " [ 1.7319054   0.05791361  4.0041634  -0.78276413 -0.78835133 -1.44047825\n",
      "  -0.6134341  -0.28748746 -0.52737723 -0.71382037]\n",
      " [-0.62979415  5.20089365 -0.78276413  9.59131554 -0.946587   -0.01751432\n",
      "  -4.36082035 -0.15938931 -1.68905335  1.16289758]\n",
      " [-1.32307846 -5.08817408 -0.78835133 -0.946587    6.69023617  0.53179628\n",
      "   6.67595386  1.66429959 -0.64994155 -1.16823206]\n",
      " [ 0.61323896  2.48305885 -1.44047825 -0.01751432  0.53179628  6.0874278\n",
      "   4.16113873  4.2272643  -2.137579    0.46609185]\n",
      " [ 0.77379598 -2.50630238 -0.6134341  -4.36082035  6.67595386  4.16113873\n",
      "  12.08191999  3.38343307 -1.37403377 -1.73293084]\n",
      " [-1.18905558  0.28921051 -0.28748746 -0.15938931  1.66429959  4.2272643\n",
      "   3.38343307  4.99225245 -1.49976115 -1.459807  ]\n",
      " [-4.96301556 -3.39323019 -0.52737723 -1.68905335 -0.64994155 -2.137579\n",
      "  -1.37403377 -1.49976115  7.49332247 -3.32330126]\n",
      " [ 3.40736329 -1.10384573 -0.71382037  1.16289758 -1.16823206  0.46609185\n",
      "  -1.73293084 -1.459807   -3.32330126  7.77512766]]\n"
     ]
    }
   ],
   "source": [
    "dot = np.dot(mat,mat.T)\n",
    "print(dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigen value: [ 3.37373058+0.j          1.82995417+1.17813902j  1.82995417-1.17813902j\n",
      " -1.88469875+1.15951213j -1.88469875-1.15951213j  0.72749514+1.14443267j\n",
      "  0.72749514-1.14443267j -1.21001934+0.57455196j -1.21001934-0.57455196j\n",
      " -0.27467285+0.j        ]\n",
      "eigen vector: [[ 0.17952804+0.j         -0.24090982-0.1793933j  -0.24090982+0.1793933j\n",
      "  -0.06823666-0.03693453j -0.06823666+0.03693453j  0.11600194+0.00180752j\n",
      "   0.11600194-0.00180752j  0.20574191-0.08152922j  0.20574191+0.08152922j\n",
      "  -0.30708865+0.j        ]\n",
      " [ 0.51395021+0.j          0.16533283-0.29184445j  0.16533283+0.29184445j\n",
      "   0.42784048+0.10253564j  0.42784048-0.10253564j -0.41135132+0.03988389j\n",
      "  -0.41135132-0.03988389j -0.27026736-0.25625521j -0.27026736+0.25625521j\n",
      "  -0.10059044+0.j        ]\n",
      " [ 0.07743127+0.j         -0.25816736+0.12085206j -0.25816736-0.12085206j\n",
      "   0.21166572-0.09730972j  0.21166572+0.09730972j  0.18843958-0.52950831j\n",
      "   0.18843958+0.52950831j -0.39283918+0.15115559j -0.39283918-0.15115559j\n",
      "  -0.21550728+0.j        ]\n",
      " [ 0.22748057+0.j         -0.16247509+0.11299668j -0.16247509-0.11299668j\n",
      "   0.67376872+0.j          0.67376872-0.j         -0.03289843+0.05356486j\n",
      "  -0.03289843-0.05356486j -0.56989575+0.j         -0.56989575-0.j\n",
      "  -0.20058369+0.j        ]\n",
      " [-0.2276698 +0.j         -0.1973081 -0.00261689j -0.1973081 +0.00261689j\n",
      "  -0.00620751+0.21495117j -0.00620751-0.21495117j -0.09194706-0.13573461j\n",
      "  -0.09194706+0.13573461j  0.07700919-0.13414259j  0.07700919+0.13414259j\n",
      "   0.26277673+0.j        ]\n",
      " [ 0.55601114+0.j          0.02452102+0.09918707j  0.02452102-0.09918707j\n",
      "  -0.27570272+0.03368833j -0.27570272-0.03368833j  0.04965629+0.14266937j\n",
      "   0.04965629-0.14266937j  0.31496781+0.06278623j  0.31496781-0.06278623j\n",
      "   0.52890756+0.j        ]\n",
      " [ 0.03708681+0.j          0.02446888-0.31125789j  0.02446888+0.31125789j\n",
      "  -0.14783973+0.33520489j -0.14783973-0.33520489j  0.14030739+0.06495122j\n",
      "   0.14030739-0.06495122j  0.04509615-0.25735495j  0.04509615+0.25735495j\n",
      "  -0.33773951+0.j        ]\n",
      " [ 0.41288883+0.j         -0.17709402+0.33215145j -0.17709402-0.33215145j\n",
      "  -0.09133945+0.12538625j -0.09133945-0.12538625j -0.02785748-0.20733182j\n",
      "  -0.02785748+0.20733182j -0.07709802-0.01828492j -0.07709802+0.01828492j\n",
      "  -0.02957934+0.j        ]\n",
      " [-0.33603797+0.j          0.57415393+0.j          0.57415393-0.j\n",
      "   0.05626575-0.02056014j  0.05626575+0.02056014j -0.03220104-0.06991335j\n",
      "  -0.03220104+0.06991335j -0.06914082+0.04627509j -0.06914082-0.04627509j\n",
      "  -0.30105493+0.j        ]\n",
      " [ 0.01121574+0.j         -0.11489541+0.21319685j -0.11489541-0.21319685j\n",
      "  -0.05031647+0.06625313j -0.05031647-0.06625313j  0.61041712+0.j\n",
      "   0.61041712-0.j          0.17473661-0.26700262j  0.17473661+0.26700262j\n",
      "  -0.50450879+0.j        ]]\n"
     ]
    }
   ],
   "source": [
    "i_val,i_vector = np.linalg.eig(mat)\n",
    "print(\"eigen value:\",i_val)\n",
    "print(\"eigen vector:\",i_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1.54109199 -0.57527037  1.51430381  1.5413305  -0.88385114\n",
      "    2.19240002  2.13947057 -1.99578154 -0.31565867 -1.70619437]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 2.94334057  1.01393206  1.72694104 -1.57339507 -1.25729437\n",
      "    3.96318893  2.32902526  2.85518367  3.23164453 -2.37037736]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.07022948 -0.05770716  1.32541033 -0.10285837  1.98968792\n",
      "    1.72070437  1.53704592 -1.09104259 -0.98579529  1.67234593]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.74109773 -0.88940505 -1.44269075 -1.40706571 -0.11655617\n",
      "   -0.07105017  3.17546047  4.50629135 -1.00961745 -1.23920647]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [-1.09406452 -0.15251971  1.04419909 -2.26035607 -1.58664026\n",
      "   -2.69167023 -0.55590824 -1.39920338 -2.69999685 -0.14778671]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.45183625  2.03821525  0.46217192  0.61386608 -3.66028719\n",
      "    1.40909536 -1.10944049  1.212072   -1.09379506  0.34811341]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [-1.2569052   1.65958063  1.53313639 -2.6382932  -4.23688828\n",
      "   -0.20499835 -1.17063292 -3.34812603 -2.01497005  0.22109491]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 1.14817577  1.5004084   0.83227016 -0.7609837  -1.599046\n",
      "    0.6618175  -2.05508147  1.30691563 -2.10387495  1.3323207 ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [-3.56411162  0.09405052 -1.07597935 -0.91654494  1.41362775\n",
      "   -0.75952863 -1.39954805  0.59785159  2.5500953   1.96707705]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.\n",
      "    0.          0.          0.          0.          0.        ]\n",
      "  [ 0.58914086 -3.36077588 -1.46078008  3.18070181 -1.82640179\n",
      "    0.76825288  0.93853935 -0.41654597 -1.16479777 -0.93316141]]]\n"
     ]
    }
   ],
   "source": [
    "import numdifftools as nd\n",
    "\n",
    "f = lambda x :  x**2\n",
    "\n",
    "jacobian = nd.Jacobian(f)(mat)\n",
    "print(jacobian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function unary_to_nary.<locals>.nary_operator.<locals>.nary_f at 0x000001B396BFF168>\n"
     ]
    }
   ],
   "source": [
    "#jacobian matrix\n",
    "from autograd import jacobian\n",
    "\n",
    "jacobian = jacobian(mat)\n",
    "print(jacobian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.2: Logistic Regression using newton method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1LWrifqkf_Kj"
   },
   "source": [
    "### Logistic regression\n",
    "Logistic regression uses an equation as the representation, very much like linear regression.\n",
    "\n",
    "Input values (x) are combined linearly using weights or coefficient values (referred to as W) to predict an output value (y). A key difference from linear regression is that the output value being modeled is a binary values (0 or 1) rather than a continuous value.<br>\n",
    "\n",
    "###  $\\hat{y}(w, x) = \\frac{1}{1+exp^{-(w_0 + w_1 * x_1 + ... + w_p * x_p)}}$\n",
    "\n",
    "#### Dataset\n",
    "The dataset is available at <strong>\"data/diabetes_data.csv\"</strong> in the respective challenge's repo.<br>\n",
    "<strong>Original Source:</strong> http://archive.ics.uci.edu/ml/machine-learning-databases/00529/diabetes_data_upload.csv. The dataset just got released in July 2020.<br><br>\n",
    "\n",
    "#### Features (X)\n",
    "\n",
    "1. Age                - Values ranging from 16-90\n",
    "2. Gender             - Binary value (Male/Female)\n",
    "3. Polyuria           - Binary value (Yes/No)\n",
    "4. Polydipsia         - Binary value (Yes/No)\n",
    "5. sudden weight loss - Binary value (Yes/No)\n",
    "6. weakness           - Binary value (Yes/No)\n",
    "7. Polyphagia         - Binary value (Yes/No)\n",
    "8. Genital thrush     - Binary value (Yes/No)\n",
    "9. visual blurring    - Binary value (Yes/No)\n",
    "10. Itching           - Binary value (Yes/No)\n",
    "11. Irritability      - Binary value (Yes/No)\n",
    "12. delayed healing   - Binary value (Yes/No)\n",
    "13. partial paresis   - Binary value (Yes/No)\n",
    "14. muscle stiffness  - Binary value (Yes/No)\n",
    "15. Alopecia          - Binary value (Yes/No)\n",
    "16. Obesity           - Binary value (Yes/No)\n",
    "\n",
    "#### Output/Target target (Y) \n",
    "17. class - Binary class (Positive/Negative)\n",
    "\n",
    "#### Objective\n",
    "To learn logistic regression and practice handling of both numerical and categorical features\n",
    "\n",
    "#### Tasks\n",
    "- Download, load the data and print first 5 and last 5 rows\n",
    "- Transform categorical features into numerical features. Use label encoding or any other suitable preprocessing technique\n",
    "- Since the age feature is in larger range, age column can be normalized into smaller scale (like 0 to 1) using different methods such as scaling, standardizing or any other suitable preprocessing technique (Example - sklearn.preprocessing.MinMaxScaler class)\n",
    "- Define X matrix (independent features) and y vector (target feature)\n",
    "- Split the dataset into 60% for training and rest 40% for testing (sklearn.model_selection.train_test_split function)\n",
    "- Train Logistic Regression Model on the training set (sklearn.linear_model.LogisticRegression class)\n",
    "- Use the trained model to predict on testing set\n",
    "- Print 'Accuracy' obtained on the testing dataset i.e. (sklearn.metrics.accuracy_score function)\n",
    "\n",
    "#### Further fun (will not be evaluated)\n",
    "- Plot loss curve (Loss vs number of iterations)\n",
    "- Preprocess data with different feature scaling methods (i.e. scaling, normalization, standardization, etc) and observe accuracies on both X_train and X_test\n",
    "- Training model on different train-test splits such as 60-40, 50-50, 70-30, 80-20, 90-10, 95-5 etc. and observe accuracies on both X_train and X_test\n",
    "- Shuffling of training samples with different *random seed values* in the train_test_split function. Check the model error for the testing data for each setup.\n",
    "- Print other classification metrics such as:\n",
    "    - classification report (sklearn.metrics.classification_report),\n",
    "    - confusion matrix (sklearn.metrics.confusion_matrix),\n",
    "    - precision, recall and f1 scores (sklearn.metrics.precision_recall_fscore_support)\n",
    "\n",
    "#### Helpful links\n",
    "- Scikit-learn documentation for logistic regression: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "- How Logistic Regression works: https://machinelearningmastery.com/logistic-regression-for-machine-learning/\n",
    "- Feature Scaling: https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "- Training testing splitting: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "- Classification metrics in sklearn: https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
    "- Use slack for doubts: https://join.slack.com/t/deepconnectai/shared_invite/zt-givlfnf6-~cn3SQ43k0BGDrG9_YOn4g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-i4VgviHf_Kk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ooYDzG4SnErt"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Download the dataset from the source\n",
    "!wget _URL_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XqZrgW_if_Kq"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Polyuria</th>\n",
       "      <th>Polydipsia</th>\n",
       "      <th>sudden weight loss</th>\n",
       "      <th>weakness</th>\n",
       "      <th>Polyphagia</th>\n",
       "      <th>Genital thrush</th>\n",
       "      <th>visual blurring</th>\n",
       "      <th>Itching</th>\n",
       "      <th>Irritability</th>\n",
       "      <th>delayed healing</th>\n",
       "      <th>partial paresis</th>\n",
       "      <th>muscle stiffness</th>\n",
       "      <th>Alopecia</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Gender Polyuria Polydipsia sudden weight loss weakness Polyphagia  \\\n",
       "0   40   Male       No        Yes                 No      Yes         No   \n",
       "1   58   Male       No         No                 No      Yes         No   \n",
       "2   41   Male      Yes         No                 No      Yes        Yes   \n",
       "3   45   Male       No         No                Yes      Yes        Yes   \n",
       "4   60   Male      Yes        Yes                Yes      Yes        Yes   \n",
       "\n",
       "  Genital thrush visual blurring Itching Irritability delayed healing  \\\n",
       "0             No              No     Yes           No             Yes   \n",
       "1             No             Yes      No           No              No   \n",
       "2             No              No     Yes           No             Yes   \n",
       "3            Yes              No     Yes           No             Yes   \n",
       "4             No             Yes     Yes          Yes             Yes   \n",
       "\n",
       "  partial paresis muscle stiffness Alopecia Obesity     class  \n",
       "0              No              Yes      Yes     Yes  Positive  \n",
       "1             Yes               No      Yes      No  Positive  \n",
       "2              No              Yes      Yes      No  Positive  \n",
       "3              No               No       No      No  Positive  \n",
       "4             Yes              Yes      Yes     Yes  Positive  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE: DO NOT CHANGE THE VARIABLE NAME(S) IN THIS CELL\n",
    "# Load the data\n",
    "data = pd.read_csv('data/diabetes_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orginal Dataframe : \n",
      "Columns :  ['Age', 'Gender', 'Polyuria', 'Polydipsia', 'sudden weight loss', 'weakness', 'Polyphagia', 'Genital thrush', 'visual blurring', 'Itching', 'Irritability', 'delayed healing', 'partial paresis', 'muscle stiffness', 'Alopecia', 'Obesity', 'class']\n",
      "No. of rows :  520\n",
      "No. of columns :  17\n"
     ]
    }
   ],
   "source": [
    "print(\"Orginal Dataframe : \")\n",
    "print(\"Columns : \", list(data.columns))\n",
    "print(\"No. of rows : \", data.shape[0])\n",
    "print(\"No. of columns : \", data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Polyuria</th>\n",
       "      <th>Polydipsia</th>\n",
       "      <th>sudden weight loss</th>\n",
       "      <th>weakness</th>\n",
       "      <th>Polyphagia</th>\n",
       "      <th>Genital thrush</th>\n",
       "      <th>visual blurring</th>\n",
       "      <th>Itching</th>\n",
       "      <th>Irritability</th>\n",
       "      <th>delayed healing</th>\n",
       "      <th>partial paresis</th>\n",
       "      <th>muscle stiffness</th>\n",
       "      <th>Alopecia</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Gender Polyuria Polydipsia sudden weight loss weakness Polyphagia  \\\n",
       "0   40   Male       No        Yes                 No      Yes         No   \n",
       "1   58   Male       No         No                 No      Yes         No   \n",
       "2   41   Male      Yes         No                 No      Yes        Yes   \n",
       "3   45   Male       No         No                Yes      Yes        Yes   \n",
       "4   60   Male      Yes        Yes                Yes      Yes        Yes   \n",
       "\n",
       "  Genital thrush visual blurring Itching Irritability delayed healing  \\\n",
       "0             No              No     Yes           No             Yes   \n",
       "1             No             Yes      No           No              No   \n",
       "2             No              No     Yes           No             Yes   \n",
       "3            Yes              No     Yes           No             Yes   \n",
       "4             No             Yes     Yes          Yes             Yes   \n",
       "\n",
       "  partial paresis muscle stiffness Alopecia Obesity     class  \n",
       "0              No              Yes      Yes     Yes  Positive  \n",
       "1             Yes               No      Yes      No  Positive  \n",
       "2              No              Yes      Yes      No  Positive  \n",
       "3              No               No       No      No  Positive  \n",
       "4             Yes              Yes      Yes     Yes  Positive  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Polyuria</th>\n",
       "      <th>Polydipsia</th>\n",
       "      <th>sudden weight loss</th>\n",
       "      <th>weakness</th>\n",
       "      <th>Polyphagia</th>\n",
       "      <th>Genital thrush</th>\n",
       "      <th>visual blurring</th>\n",
       "      <th>Itching</th>\n",
       "      <th>Irritability</th>\n",
       "      <th>delayed healing</th>\n",
       "      <th>partial paresis</th>\n",
       "      <th>muscle stiffness</th>\n",
       "      <th>Alopecia</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>515</td>\n",
       "      <td>39</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>516</td>\n",
       "      <td>48</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>517</td>\n",
       "      <td>58</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>518</td>\n",
       "      <td>32</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>519</td>\n",
       "      <td>42</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Gender Polyuria Polydipsia sudden weight loss weakness Polyphagia  \\\n",
       "515   39  Female      Yes        Yes                Yes       No        Yes   \n",
       "516   48  Female      Yes        Yes                Yes      Yes        Yes   \n",
       "517   58  Female      Yes        Yes                Yes      Yes        Yes   \n",
       "518   32  Female       No         No                 No      Yes         No   \n",
       "519   42    Male       No         No                 No       No         No   \n",
       "\n",
       "    Genital thrush visual blurring Itching Irritability delayed healing  \\\n",
       "515             No              No     Yes           No             Yes   \n",
       "516             No              No     Yes          Yes             Yes   \n",
       "517             No             Yes      No           No              No   \n",
       "518             No             Yes     Yes           No             Yes   \n",
       "519             No              No      No           No              No   \n",
       "\n",
       "    partial paresis muscle stiffness Alopecia Obesity     class  \n",
       "515             Yes               No       No      No  Positive  \n",
       "516             Yes               No       No      No  Positive  \n",
       "517             Yes              Yes       No     Yes  Positive  \n",
       "518              No               No      Yes      No  Negative  \n",
       "519              No               No       No      No  Negative  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hjCRzhp_f_Kw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "# Handle categorical/binary columns\n",
    "\n",
    "categorical = list(data.columns)\n",
    "categorical.remove(\"Age\")\n",
    "print(len(categorical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Male' 'Female']\n",
      "['No' 'Yes']\n",
      "['Yes' 'No']\n",
      "['No' 'Yes']\n",
      "['Yes' 'No']\n",
      "['No' 'Yes']\n",
      "['No' 'Yes']\n",
      "['No' 'Yes']\n",
      "['Yes' 'No']\n",
      "['No' 'Yes']\n",
      "['Yes' 'No']\n",
      "['No' 'Yes']\n",
      "['Yes' 'No']\n",
      "['Yes' 'No']\n",
      "['Yes' 'No']\n",
      "['Positive' 'Negative']\n"
     ]
    }
   ],
   "source": [
    "for i in categorical:\n",
    "    print(data[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "data[categorical] = data[categorical].apply(encoder.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3aNK0lA1f_Kz"
   },
   "outputs": [],
   "source": [
    "# Normalize the age feature\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data.Age = scaler.fit_transform(pd.DataFrame(data.Age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tqCVUtIUf_K3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Polyuria</th>\n",
       "      <th>Polydipsia</th>\n",
       "      <th>sudden weight loss</th>\n",
       "      <th>weakness</th>\n",
       "      <th>Polyphagia</th>\n",
       "      <th>Genital thrush</th>\n",
       "      <th>visual blurring</th>\n",
       "      <th>Itching</th>\n",
       "      <th>Irritability</th>\n",
       "      <th>delayed healing</th>\n",
       "      <th>partial paresis</th>\n",
       "      <th>muscle stiffness</th>\n",
       "      <th>Alopecia</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.391892</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  Gender  Polyuria  Polydipsia  sudden weight loss  weakness  \\\n",
       "0  0.324324       1         0           1                   0         1   \n",
       "1  0.567568       1         0           0                   0         1   \n",
       "2  0.337838       1         1           0                   0         1   \n",
       "3  0.391892       1         0           0                   1         1   \n",
       "4  0.594595       1         1           1                   1         1   \n",
       "\n",
       "   Polyphagia  Genital thrush  visual blurring  Itching  Irritability  \\\n",
       "0           0               0                0        1             0   \n",
       "1           0               0                1        0             0   \n",
       "2           1               0                0        1             0   \n",
       "3           1               1                0        1             0   \n",
       "4           1               0                1        1             1   \n",
       "\n",
       "   delayed healing  partial paresis  muscle stiffness  Alopecia  Obesity  \\\n",
       "0                1                0                 1         1        1   \n",
       "1                0                1                 0         1        0   \n",
       "2                1                0                 1         1        0   \n",
       "3                1                0                 0         0        0   \n",
       "4                1                1                 1         1        1   \n",
       "\n",
       "   class  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Uc-BEzqf_K-"
   },
   "outputs": [],
   "source": [
    "# Define your X and y\n",
    "X = data.drop(\"class\",axis = 1).values\n",
    "y = data[\"class\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DIiMrIaajX-Q"
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing here\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape  :  (312, 16)\n",
      "y_train shape  :  (312,)\n",
      "X_test shape :  (208, 16)\n",
      "y_test shape :  (208,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape  : \", X_train.shape)\n",
    "print(\"y_train shape  : \", y_train.shape)\n",
    "print(\"X_test shape : \", X_test.shape)\n",
    "print(\"y_test shape : \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, weights):\n",
    "    '''Predict class for X.\n",
    "    For the given dataset, predicted vector has only values 0/1\n",
    "    Args:\n",
    "        X : Numpy array (num_samples, num_features)\n",
    "        weights : Model weights for logistic regression\n",
    "    Returns:\n",
    "        Binary predictions : (num_samples,)\n",
    "    '''\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    z = np.dot(X, weights)\n",
    "    logits = sigmoid(z)\n",
    "    y_pred = logits.round()\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "        '''Sigmoid function: f:R->(0,1)\n",
    "        Args:\n",
    "            z : A numpy array (num_samples,)\n",
    "        Returns:\n",
    "            A numpy array where sigmoid function applied to every element\n",
    "        '''\n",
    "        ### START CODE HERE\n",
    "        sig_z = 1 / (1 + np.exp(-z))\n",
    "        ### END CODE HERE\n",
    "        \n",
    "        assert (z.shape==sig_z.shape), 'Error in sigmoid implementation. Check carefully'\n",
    "        return sig_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(y_true, y_pred):\n",
    "    '''Calculate cross entropy loss\n",
    "    Note: Cross entropy is defined for multiple classes/labels as well\n",
    "    but for this dataset we only need binary cross entropy loss\n",
    "    Args:\n",
    "        y_true : Numpy array of true values (0/1) of size (num_samples,)\n",
    "        y_pred : Numpy array of predicted values (probabilites) of size (num_samples,)\n",
    "    Returns:\n",
    "        Cross entropy loss: A scalar value\n",
    "    '''\n",
    "    # Fix 0 values in y_pred\n",
    "    y_pred = np.maximum(np.full(y_pred.shape, 1e-7), np.minimum(np.full(y_pred.shape, 1-1e-7), y_pred))\n",
    "    \n",
    "    ### START CODE HERE\n",
    "    ce_loss = np.mean(- y_true * np.log(y_pred) - (1 - y_true) * np.log(1 - y_pred))\n",
    "    ### END CODE HERE_\n",
    "    \n",
    "    return ce_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_optimization(X, y, max_iterations=25):\n",
    "    '''Implement netwon method for optimizing weights\n",
    "    Args:\n",
    "        X : Numpy array (num_samples, num_features)\n",
    "        max_iterations : Max iterations to update the weights\n",
    "    Returns:\n",
    "        Optimal weights (num_features,)\n",
    "    '''\n",
    "    num_samples = X.shape[0]\n",
    "    num_features = X.shape[1]\n",
    "    # Initialize random weights\n",
    "    weights = np.zeros(num_features,)\n",
    "    # Initialize losses\n",
    "    losses = []\n",
    "    \n",
    "    # Newton Method\n",
    "    for i in range(max_iterations):\n",
    "        # Predict/Calculate probabilties using sigmoid function\n",
    "        z = predict(X, weights)\n",
    "        y_pred = sigmoid(z)\n",
    "        \n",
    "        # Define gradient for J (cost function) i.e. cross entropy loss\n",
    "        gradient = (1 / num_samples) * np.dot(X.T, (y_pred - y))  \n",
    "        \n",
    "        # Define hessian matrix for cross entropy loss\n",
    "        hessian = (1 / num_samples) * X.T.dot(np.diag(y_pred * (1 - y_pred))).dot(X)\n",
    "        \n",
    "        # Update the model using hessian matrix and gradient computed\n",
    "        weights -= np.dot(np.linalg.pinv(hessian), gradient)\n",
    "        \n",
    "        # Calculate cross entropy loss\n",
    "        loss = cross_entropy_loss(y, y_pred)\n",
    "        # Append it\n",
    "        losses.append(loss)\n",
    "\n",
    "    return weights, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(520, 16)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train weights\n",
    "weights, losses = newton_optimization(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curve\n",
    "plt.plot([i+1 for i in range(len(losses))], losses)\n",
    "plt.title(\"Loss curve\")\n",
    "plt.xlabel(\"Iteration num\")\n",
    "plt.ylabel(\"Cross entropy curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy in testing set by our model: 0.8653846153846154\n"
     ]
    }
   ],
   "source": [
    "our_model_test_acuracy = accuracy_score(y_test, predict(X_test, weights))\n",
    "\n",
    "print(f\"\\nAccuracy in testing set by our model: {our_model_test_acuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare with the scikit learn implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qhvibx3Xf_LB"
   },
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = LogisticRegression(solver='newton-cg', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ndXHgNLxf_LD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=1,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model. Wait! We will complete this step for you ;)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oHOeLfjFjeNh"
   },
   "outputs": [],
   "source": [
    "# Predict on testing set X_test\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eE5g0uoYf_LG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy in testing set by sklearn model: 0.9278846153846154\n"
     ]
    }
   ],
   "source": [
    "# Print Accuracy on testing set\n",
    "sklearn_test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nAccuracy in testing set by sklearn model: {sklearn_test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "task_2_logistic_diabetes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
